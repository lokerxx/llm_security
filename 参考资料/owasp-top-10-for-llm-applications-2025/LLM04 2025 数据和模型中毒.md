# LLM04:2025 数据和模型中毒

## 描述

数据中毒是指在预训练、微调或嵌入数据时被操控，导致模型出现漏洞、后门或偏差。这种操控可能会破坏模型的安全性、性能或伦理行为，从而导致有害输出或能力受损。常见风险包括模型性能下降、偏见或有毒内容生成，以及下游系统被利用。

数据中毒可能影响LLM生命周期的不同阶段，包括：
- **预训练**：从通用数据中学习。
- **微调**：将模型适配于特定任务。
- **嵌入**：将文本转换为数值向量。

理解这些阶段有助于识别漏洞来源。数据中毒属于完整性攻击，因为篡改训练数据会影响模型做出准确预测的能力。特别是外部数据源中可能包含未经验证或恶意内容，风险尤为显著。

此外，共享库或开源平台分发的模型也存在数据中毒之外的风险，例如通过恶意“Pickling”技术嵌入的恶意软件，这些软件在加载模型时可能执行有害代码。中毒还可能导致模型中植入后门，表现为模型行为正常，但在特定触发条件下发生变化，这种“休眠特工”行为难以检测和测试。

---

## 常见漏洞示例

1. 恶意行为者在训练过程中引入有害数据，导致模型生成偏差输出。例如，“**Split-View Data Poisoning**”和“**Frontrunning Poisoning**”技术利用模型训练的动态实现攻击。  
   **参考链接**: [Split-View Data Poisoning](https://example.com) | [Frontrunning Poisoning](https://example.com)

2. 攻击者直接在训练过程中注入有害内容，影响模型输出质量。

3. 用户在交互中无意注入敏感或专有信息，这些信息可能在后续输出中暴露。

4. 未验证的训练数据增加了生成偏差或错误输出的风险。

5. 缺乏资源访问限制可能允许摄入不安全的数据，导致偏差输出。

---

## 预防和缓解策略

1. **跟踪数据来源和转化**  
   使用工具（如OWASP CycloneDX或ML-BOM）跟踪数据来源和转化，在模型开发的所有阶段验证数据的合法性。

2. **严格审查数据供应商**  
   验证模型输出是否符合可信来源，以检测中毒迹象。

3. **实施严格的沙盒机制**  
   限制模型接触未经验证的数据源，使用异常检测技术过滤对抗性数据。

4. **定制模型**  
   针对不同用例使用特定数据集进行微调，有助于基于既定目标生成更准确的输出。

5. **确保基础设施控制**  
   防止模型访问非预期的数据源。

6. **使用数据版本控制（DVC）**  
   跟踪数据集中的更改，检测操控情况。版本控制对于维护模型完整性至关重要。

7. **存储用户提供信息**  
   将用户提供的信息存储在向量数据库中，避免重新训练整个模型即可进行调整。

8. **测试模型的鲁棒性**  
   使用红队活动和对抗性技术（如联邦学习）测试模型的鲁棒性，以尽量减少数据扰动的影响。

9. **监控训练损失**  
   分析模型行为以检测中毒迹象，使用阈值检测异常输出。

10. **推理期间结合RAG和基础技术**  
      集成检索增强生成（RAG）和基础技术，降低幻觉生成的风险。

---

## 示例攻击场景

### 场景 #1: **输出偏差**
攻击者通过操控训练数据或使用提示注入技术，使模型传播错误信息。

### 场景 #2: **有毒数据影响**
未经过滤的有毒数据可能导致有害或偏差输出，传播危险信息。

### 场景 #3: **伪造文档训练**
恶意行为者或竞争对手创建伪造文档用于训练，导致模型输出反映这些不准确的信息。

### 场景 #4: **提示注入引导错误数据**
不充分的过滤措施允许攻击者通过提示注入插入误导性数据，导致输出被破坏。

### 场景 #5: **后门触发**  
攻击者使用中毒技术在模型中插入后门触发器。这可能使攻击者绕过身份验证、进行数据窃取或执行隐藏命令。